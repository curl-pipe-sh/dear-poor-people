#!/usr/bin/env sh
# description: curl, but uses wget behind the scenes
# icon: mdi:download
# curl-like wrapper using wget
# Supports a practical subset of curl flags:
#  -s, -S, -L, -o/-O, -d, -H, -I, -f, -k, -A, -u, -m/--max-time,
#  --connect-timeout, --retry, -x (proxy), -w '%{http_code}'
# Combined short flags like -sL, -sSf, -oFILE, -dDATA, -HHeader work.

set -eu

# shellcheck disable=SC2034  # Used by usage function
SCRIPT_NAME="poorcurl"

# Source echo utilities - this line gets replaced during templating
# shellcheck disable=SC1091  # File is included via templating
. lib/echo.sh # <TEMPLATE>
# shellcheck disable=SC1091  # File is included via templating
. lib/download.sh # <TEMPLATE>

usage() {
  echo "Usage: ${SCRIPT_NAME} [--debug] [--trace] [options] URL" >&2
  echo
  echo "Options:" >&2
  echo "  --debug                Enable debug output" >&2
  echo "  --trace                Enable shell tracing (set -x)" >&2
  echo "  -s                     silent" >&2
  echo "  -S                     show errors (useful with -s)" >&2
  echo "  -L                     follow redirects" >&2
  echo "  -o FILE | -oFILE       write to FILE" >&2
  echo "  -O                     write to remote name" >&2
  echo "  -d DATA | -dDATA       send POST with DATA" >&2
  echo "  -H LINE | -HLINE       add request header (repeatable)" >&2
  echo "  -I                     headers only (HEAD-ish)" >&2
  echo "  -f                     fail on HTTP >= 400 (no body, exit 22)" >&2
  echo "  -k                     insecure TLS (no cert check)" >&2
  echo "  -A UA                  set User-Agent" >&2
  echo "  -u USER:PASS           HTTP basic auth" >&2
  echo "  -m SEC / --max-time SEC  overall timeout" >&2
  echo "  --connect-timeout SEC  connect timeout" >&2
  echo "  --retry N              retry count" >&2
  echo "  -x URL                 proxy (http/https)" >&2
  echo "  -w '%{http_code}'      print HTTP status code" >&2
  echo "  -h, --help             this help" >&2
}

# Use the common wget feature detection from lib/download.sh
get_wget_flags

outfile=
remote_name=
quiet=
showerr=
redir=
postdata=
headers=
head_only=
fail=
insecure=
user_agent=
auth=
max_time=
connect_timeout=
retries=
proxy=
write_out=

url=

# Parse args incl. combined short flags
while [ $# -gt 0 ]
do
  case "$1" in
    --debug)
      DEBUG=1
      export DEBUG  # Export for use by echo.sh functions
      shift
      ;;
    --trace)
      set -x
      shift
      ;;
    --help|-h)
      usage
      exit 0
      ;;
    --max-time)
      [ $# -ge 2 ] || { echo_error "curl: --max-time needs seconds"; exit 2; }
      max_time="$2"
      shift 2
      ;;
    --connect-timeout)
      [ $# -ge 2 ] || { echo_error "curl: --connect-timeout needs seconds"; exit 2; }
      connect_timeout="$2"
      shift 2
      ;;
    --retry)
      [ $# -ge 2 ] || { echo_error "curl: --retry needs count"; exit 2; }
      retries="$2"
      shift 2
      ;;
    -w)
      [ $# -ge 2 ] || { echo_error "curl: -w needs format"; exit 2; }
      write_out="$2"
      shift 2
      ;;
    -x)
      [ $# -ge 2 ] || { echo_error "curl: -x needs proxy URL"; exit 2; }
      proxy="$2"
      shift 2
      ;;
    http://*|https://*|ftp://*)
      url="$1"
      shift
      break
      ;;
    -[!-]*)
      opts=${1#-}
      while [ -n "$opts" ]
      do
        c=${opts%"${opts#?}"}
        rest=${opts#?}
        case "$c" in
          s)
            quiet=1
            opts="${rest}"
            ;;
          S)
            showerr=1
            opts="${rest}"
            ;;
          L)
            redir=1
            opts="${rest}"
            ;;
          O)
            remote_name=1
            opts="${rest}"
            ;;
          I)
            head_only=1
            opts="${rest}"
            ;;
          f)
            fail=1
            opts="${rest}"
            ;;
          k)
            insecure=1
            opts="${rest}"
            ;;
          A)
            if [ -n "$rest" ]
            then
              user_agent="${rest}"
              opts=
            else
              shift
              [ $# -gt 0 ] || { echo_error "curl: -A needs UA"; exit 2; }
              user_agent="$1"
              opts=
            fi
            ;;
          u)
            if [ -n "$rest" ]
            then
              auth="${rest}"
              opts=
            else
              shift
              [ $# -gt 0 ] || { echo_error "curl: -u needs USER:PASS"; exit 2; }
              auth="$1"
              opts=
            fi
            ;;
          m)
            if [ -n "$rest" ]
            then
              max_time="${rest}"
              opts=
            else
              shift
              [ $# -gt 0 ] || { echo_error "curl: -m needs seconds"; exit 2; }
              max_time="$1"
              opts=
            fi
            ;;
          o)
            if [ -n "$rest" ]
            then
              outfile="${rest}"
              opts=
            else
              shift
              [ $# -gt 0 ] || { echo_error "curl: -o needs file"; exit 2; }
              outfile="$1"
              opts=
            fi
            ;;
          d)
            if [ -n "$rest" ]
            then
              postdata="${rest}"
              opts=
            else
              shift
              [ $# -gt 0 ] || { echo_error "curl: -d needs data"; exit 2; }
              postdata="$1"
              opts=
            fi
            ;;
          H)
            if [ -n "$rest" ]
            then
              headers="${headers} ${WGET_HEADER}=${rest}"
              opts=
            else
              shift
              [ $# -gt 0 ] || { echo_error "curl: -H needs header"; exit 2; }
              headers="${headers} ${WGET_HEADER}=${1}"
              opts=
            fi
            ;;
          *)
            echo_error "curl: unsupported -$c in '$1'"
            usage
            exit 2
            ;;
        esac
      done
      shift
      ;;
    *)
      url="$1"
      shift
      break
      ;;
  esac
done

# If URL not yet set, next arg is URL
if [ -z "${url:-}" ] && [ $# -gt 0 ]
then
  url="$1"
  shift
fi
[ -n "${url:-}" ] || { usage; exit 2; }

# Build wget command
set -- wget
[ -n "${quiet:-}" ] && set -- "$@" -q
[ -n "${redir:-}" ] && [ -n "$WGET_REDIRECT" ] && set -- "$@" "${WGET_REDIRECT}"
[ -n "$postdata" ] && set -- "$@" "$WGET_POSTDATA=${postdata}"
# shellcheck disable=SC2086 # headers contains multiple arguments
[ -n "$headers" ] && set -- "$@" ${headers}
[ -n "${head_only:-}" ] && set -- "$@" "${WGET_SRVR}" --spider
[ -n "${insecure:-}" ] && [ -n "$WGET_NOCHK" ] && set -- "$@" "${WGET_NOCHK}"
[ -n "$user_agent" ] && [ -n "$WGET_UA" ] && set -- "$@" "$WGET_UA=${user_agent}"
if [ -n "$auth" ]
then
  case "$WGET_AUTH_PASS" in
    '') set -- "$@" "$WGET_AUTH_USER=${auth}" ;;                 # BusyBox style USER:PASS
    *)  set -- "$@" "$WGET_AUTH_USER=${auth%%:*}" "$WGET_AUTH_PASS=${auth#*:}" ;;
  esac
fi
[ -n "$connect_timeout" ] && [ -n "$WGET_CONNTO" ] && set -- "$@" "$WGET_CONNTO=${connect_timeout}"
[ -n "$max_time" ] && set -- "$@" "$WGET_TIMEOUT=${max_time}"
[ -n "$retries" ] && [ -n "$WGET_RETRY" ] && set -- "$@" "$WGET_RETRY=${retries}"
if [ -n "$proxy" ]
then
  # Enable proxy via env executes (works on GNU & BusyBox)
  set -- "$@" -e use_proxy=yes
  case "$url" in
    https://*) set -- "$@" -e "https_proxy=${proxy}" ;;
    http://*)  set -- "$@" -e "http_proxy=${proxy}" ;;
    *)         set -- "$@" -e "http_proxy=${proxy}" -e "https_proxy=${proxy}" ;;
  esac
fi

# Output selection
if [ -n "${remote_name:-}" ]
then
  : # default wget behavior uses remote name
elif [ -n "${outfile:-}" ]
then
  set -- "$@" -O "$outfile"
else
  set -- "$@" -O -
fi

# --fail emulation needs status; also -w http_code needs status
need_status=
[ -n "${fail:-}" ] && need_status=1
[ "${write_out:-}" = "%{http_code}" ] && need_status=1

if [ -n "${need_status:-}" ] && [ -z "${head_only:-}" ]
then
  # capture headers to parse status (stderr) and body (stdout)
  out=$(mktemp)
  err=$(mktemp)
  trap 'rm -f "$out" "$err"' EXIT
  if ! "$@" "${WGET_SRVR}" "$url" >"$out" 2>"$err"
  then
    [ -n "${showerr:-}" ] && cat "$err" >&2
    exit 1
  fi

  status=$(grep '^  HTTP/' "$err" | tail -1 | awk '{print $2}')
  [ -z "$status" ] && status=000

  if [ -n "${fail:-}" ] && [ "$status" -ge 400 ] 2>/dev/null
  then
    [ -n "${showerr:-}" ] && echo_error "curl: (22) HTTP status $status"
    exit 22
  fi

  cat "$out"

  if [ "${write_out:-}" = "%{http_code}" ]
  then
    printf "%s" "$status"
  fi
  exit 0

else
  # Simple path (maybe header-only or no fail/w)
  if [ "${write_out:-}" = "%{http_code}" ] && [ -n "${head_only:-}" ]
  then
    # get status from HEAD-ish request
    err=$(mktemp)
    trap 'rm -f "$err"' EXIT
    if ! "$@" "$url" 2>"$err"
    then
      [ -n "${showerr:-}" ] && cat "$err" >&2
      exit 1
    fi
    status=$(grep '^  HTTP/' "$err" | tail -1 | awk '{print $2}')
    [ -z "$status" ] && status=000
    printf "%s" "$status"
    exit 0
  fi
  exec "$@" "$url"
fi
